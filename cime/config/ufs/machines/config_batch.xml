<?xml version="1.0"?>
<config_batch version="2.1">
  <!--
     File:    config_batch.xml
     Purpose: abstract out the parts of run scripts that are different, and use this configuration to
     create cesm run scripts from a single template.

     batch_system:     the batch system type and version
     batch_query:      the batch query command for each batch system.
     batch_redirect:   Whether a redirect character is needed to submit jobs.
     batch_directive:  The string that prepends a batch directive for the batch system.
     jobid_pattern:    A perl regular expression used to filter out the returned job id from a
                       queue submission.

 ===============================================================
 batch_system
 ===============================================================
 The batch_system and associated tags are meant for configuring batch systems and
 queues across machines.  The batch_system tag denotes the name for a particular
 batch system, these can either be shared between one or more machines, or can be
 defined for a specific machine if need be.

 Machine specific entries take precidence over generic entries, directives are appended

 queues:
 one or more queues can be defined per batch_system. if the attribute default="true"
 is used, then that queue will be used by default. Alternatively, multiple queues can
 be used.  The following variables can be used to choose a queue :
 walltimemin: Giving the minimum amount of walltime for the queue.
 walltimemax: The maximum amount of walltime for a queue.
 nodemin:      The minimum node count required to use this queue.
 nodemax:      The maximum node count required to use this queue.
 jobmin:      The minimum task count required to use this queue. This should only rarely be used to select queues that only use a fraction of a node. This cannot be used in conjuction with nodemin.
 jobmax:      The maximum task count required to use this queue. This should only rarely be used to select queues that only use a fraction of a node. This cannot be used in conjuction with nodemax.
    -->
  <batch_system type="template" >
    <batch_query args=""></batch_query>
    <batch_submit></batch_submit>
    <batch_redirect></batch_redirect>
    <batch_directive></batch_directive>
    <directives>
      <directive></directive>
    </directives>
  </batch_system>

  <batch_system type="none" >
    <batch_query args=""></batch_query>
    <batch_submit></batch_submit>
    <batch_redirect></batch_redirect>
    <batch_directive></batch_directive>
    <directives>
      <directive></directive>
    </directives>
  </batch_system>

  <batch_system type="cobalt" >
    <batch_query>qstat</batch_query>
    <batch_submit>qsub</batch_submit>
    <batch_cancel>qdel</batch_cancel>
    <batch_env>-v</batch_env>
    <batch_directive></batch_directive>
    <jobid_pattern>(\d+)</jobid_pattern>
    <depend_string> --dependencies</depend_string>
    <walltime_format>%H:%M:%s</walltime_format>
    <batch_mail_flag>-M</batch_mail_flag>
    <batch_mail_type_flag></batch_mail_type_flag>
    <batch_mail_type></batch_mail_type>
    <submit_args>
      <arg flag="--cwd" name="CASEROOT"/>
      <arg flag="-A" name="PROJECT"/>
      <arg flag="-t" name="JOB_WALLCLOCK_TIME"/>
      <!-- space required at beginning of name -->
      <arg flag="-n" name=" $TOTALPES / $MAX_MPITASKS_PER_NODE"/>
      <arg flag="-q" name="JOB_QUEUE"/>
      <arg flag="--mode script"/>
    </submit_args>
  </batch_system>

  <batch_system type="cobalt_theta" >
    <batch_query>qstat</batch_query>
    <batch_submit>qsub</batch_submit>
    <batch_cancel>qdel</batch_cancel>
    <batch_env>--env</batch_env>
    <batch_directive>#COBALT</batch_directive>
    <jobid_pattern>(\d+)</jobid_pattern>
    <depend_string> --dependencies</depend_string>
    <batch_mail_flag>-M</batch_mail_flag>
    <batch_mail_type_flag></batch_mail_type_flag>
    <batch_mail_type></batch_mail_type>
    <submit_args>
      <arg flag="-A" name="PROJECT"/>
      <arg flag="-t" name="JOB_WALLCLOCK_TIME"/>
      <arg flag="-n" name=" $TOTALPES/$MAX_MPITASKS_PER_NODE"/>
      <arg flag="-q" name="JOB_QUEUE"/>
      <arg flag="--mode script"/>
    </submit_args>
  </batch_system>

  <batch_system type="lsf">
    <batch_query args=" -w" >bjobs</batch_query>
    <batch_submit>bsub</batch_submit>
    <batch_cancel>bkill</batch_cancel>
    <batch_redirect>&lt;</batch_redirect>
    <batch_env> </batch_env>
    <batch_directive>#BSUB</batch_directive>
    <jobid_pattern>&lt;(\d+)&gt;</jobid_pattern>
    <depend_string> -w 'done(jobid)'</depend_string>
    <depend_allow_string> -w 'ended(jobid)'</depend_allow_string>
    <depend_separator>&amp;&amp;</depend_separator>
    <walltime_format>%H:%M</walltime_format>
    <batch_mail_flag>-u</batch_mail_flag>
    <batch_mail_type_flag></batch_mail_type_flag>
    <batch_mail_type></batch_mail_type>
    <directives>
      <directive                       > -J {{ job_id }} </directive>
      <directive                       > -n {{ total_tasks }} </directive>
      <directive                       > -W $JOB_WALLCLOCK_TIME </directive>
      <directive default="cesm.stdout" > -o {{ job_id }}.%J  </directive>
      <directive default="cesm.stderr" > -e {{ job_id }}.%J  </directive>
    </directives>
  </batch_system>

  <batch_system type="pbs" >
    <batch_query args="-f" >qstat</batch_query>
    <batch_submit>qsub </batch_submit>
    <batch_cancel>qdel</batch_cancel>
    <batch_env>-v</batch_env>
    <batch_directive>#PBS</batch_directive>
    <jobid_pattern>^(\S+)$</jobid_pattern>
    <depend_string> -W depend=afterok:jobid</depend_string>
    <depend_allow_string> -W depend=afterany:jobid</depend_allow_string>
    <depend_separator>:</depend_separator>
    <walltime_format>%H:%M:%S</walltime_format>
    <batch_mail_flag>-M</batch_mail_flag>
    <batch_mail_type_flag>-m</batch_mail_type_flag>
    <batch_mail_type>, bea, b, e, a</batch_mail_type>
    <submit_args>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="-l walltime=" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-A" name="$PROJECT"/>
    </submit_args>
    <directives>
      <directive>-N {{ job_id }}</directive>
      <directive default="n"> -r {{ rerunnable }} </directive>
      <!-- <directive> -j oe {{ job_id }} </directive> -->
      <directive> -j oe </directive>
      <directive> -V </directive>
    </directives>
  </batch_system>

  <batch_system type="slurm" >
    <batch_query per_job_arg="-j">squeue</batch_query>
    <batch_cancel>scancel</batch_cancel>
    <batch_directive>#SBATCH</batch_directive>
    <jobid_pattern>(\d+)$</jobid_pattern>
    <depend_string> --dependency=afterok:jobid</depend_string>
    <depend_allow_string> --dependency=afterany:jobid</depend_allow_string>
    <depend_separator>,</depend_separator>
    <walltime_format>%H:%M:%S</walltime_format>
    <batch_mail_flag>--mail-user</batch_mail_flag>
    <batch_mail_type_flag>--mail-type</batch_mail_type_flag>
    <batch_mail_type>none, all, begin, end, fail</batch_mail_type>
    <directives>
      <directive> --job-name={{ job_id }}</directive>
      <directive> --nodes={{ num_nodes }}</directive>
      <directive> --ntasks-per-node={{ tasks_per_node }}</directive>
      <directive> --output={{ job_id }}   </directive>
      <directive> --exclusive                        </directive>
    </directives>
  </batch_system>

  <batch_system MACH="cheyenne" type="pbs">
    <directives queue="regular">
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
      <directive> -l select={{ num_nodes }}:ncpus={{ max_tasks_per_node }}:mpiprocs={{ tasks_per_node }}:ompthreads={{ thread_count }}</directive>
    </directives>

    <directives queue="premium">
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
      <directive> -l select={{ num_nodes }}:ncpus={{ max_tasks_per_node }}:mpiprocs={{ tasks_per_node }}:ompthreads={{ thread_count }}</directive>
    </directives>

    <directives queue="economy">
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
      <directive> -l select={{ num_nodes }}:ncpus={{ max_tasks_per_node }}:mpiprocs={{ tasks_per_node }}:ompthreads={{ thread_count }}</directive>
    </directives>

    <directives queue="share">
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
      <directive> -l select=1:mpiprocs={{ total_tasks }}:ompthreads={{ thread_count }}</directive>
    </directives>

    <!-- Unknown queues use the batch directives for the regular queue -->
    <unknown_queue_directives>regular</unknown_queue_directives>

    <queues>
      <queue walltimemax="12:00:00" nodemin="1" nodemax="4032">regular</queue>
      <queue walltimemax="12:00:00" nodemin="1" nodemax="4032">premium</queue>
      <queue default="true" walltimemax="06:00:00" jobmin="1" jobmax="18">share</queue>
      <queue walltimemax="12:00:00" nodemin="1" nodemax="4032">economy</queue>
    </queues>
  </batch_system>

  <batch_system MACH="hera" type="slurm" >
    <batch_submit>sbatch</batch_submit>
    <submit_args>
      <arg flag="--time" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="--account" name="$PROJECT"/>
    </submit_args>
    <directives>
      <directive>--partition=hera</directive>
    </directives>
    <queues>
      <queue default="true" walltimemax="08:00:00" nodemin="1" nodemax="210">batch</queue>
      <queue walltimemax="00:30:00" nodemin="1" nodemax="210">debug</queue>
    </queues>
  </batch_system>

  <batch_system MACH="orion" type="slurm" >
    <batch_submit>sbatch</batch_submit>
    <submit_args>
      <arg flag="--time" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="--account" name="$PROJECT"/>
    </submit_args>
    <directives>
      <directive>--partition=orion</directive>
    </directives>
    <queues>
      <queue default="true" walltimemax="08:00:00" nodemin="1" nodemax="210">batch</queue>
      <queue walltimemax="00:30:00" nodemin="1" nodemax="210">debug</queue>
    </queues>
  </batch_system>

  <batch_system MACH="jet" type="slurm" >
    <batch_submit>sbatch</batch_submit>
    <submit_args>
      <arg flag="--time" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="--account" name="$PROJECT"/>
    </submit_args>
    <directives>
      <directive>--partition=kjet</directive>
    </directives>
    <queues>
      <queue walltimemax="01:00:00" nodemin="1" nodemax="171">batch</queue>
    </queues>
  </batch_system>

  <batch_system MACH="stampede2-skx" type="slurm" >
    <batch_submit>ssh login1.stampede2.tacc.utexas.edu cd $CASEROOT ; sbatch</batch_submit>
    <submit_args>
      <arg flag="--time" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-p" name="$JOB_QUEUE"/>
      <arg flag="--account" name="$PROJECT"/>
    </submit_args>
    <queues>
      <queue walltimemax="48:00:00" nodemin="1" nodemax="256" default="true">skx-normal</queue>
      <queue walltimemax="02:00:00" nodemin="1" nodemax="4" >skx-dev</queue>
    </queues>
  </batch_system>

  <batch_system MACH="gaea" type="slurm" >
    <batch_submit>sbatch</batch_submit>
    <jobid_pattern>Submitted batch job (\d+) on cluster .*</jobid_pattern>
    <submit_args>
      <arg flag="--time" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="--qos" name="$JOB_QUEUE"/>
      <arg flag="--account" name="$CHARGE_ACCOUNT"/>
    </submit_args>
    <directives>
      <directive>--clusters=c4</directive>
    </directives>
    <queues>
      <queue walltimemax="00:30:00" nodemin="1" nodemax="171">debug</queue>
    </queues>
  </batch_system>
</config_batch>

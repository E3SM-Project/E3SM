<?xml version="1.0"?>
<config_batch version="1.0.0">
  <!--
     File:    config_batch.xml
     Purpose: abstract out the parts of run scripts that are different, and use this configuration to
     create cesm run scripts from a single template.

     batch_system:     the batch system type and version
     batch_query:      the batch query command for each batch system.
     batch_redirect:   Whether a redirect character is needed to submit jobs.
     batch_directive:  The string that prepends a batch directive for the batch system.
     jobid_pattern:    A perl regular expression used to filter out the returned job id from a
                       queue submission.
     depend_pattern:

 ===============================================================
 batch_system
 ===============================================================
 The batch_system and associated tags are meant for configuring batch systems and
 queues across machines.  The batch_system tag denotes the name for a particular
 batch system, these can either be shared between one or more machines, or can be
 defined for a specific machine if need be.
 queues:
 one or more queues can be defined per batch_system. if the attribute default="true"
 is used, then that queue will be used by default. Alternatively, multiple queues can
 be used.  The following variables can be used to choose a queue :
 walltimemin: Giving the minimum amount of walltime for the queue.
 walltimemax: The maximum amount of walltime for a queue.
 jobmin:      The minimum node count required to use this queue.
 jobmax:      The maximum node count required to use this queue.

 walltimes:
 Denotes the walltimes that can be used for a particular machine.
 walltime: as before, if default="true" is defined, this walltime will be used
 by default.
 Alternatively, ccsm_estcost must be used to choose the queue based on the estimated cost of the run.
    -->
  <batch_system type="template" version="x.y">
    <batch_query args=""></batch_query>
    <batch_submit></batch_submit>
    <batch_redirect></batch_redirect>
    <batch_directive></batch_directive>
    <directives>
      <directive name=""></directive>
    </directives>
  </batch_system>

  <batch_system type="none" version="x.y">
    <batch_query args=""></batch_query>
    <batch_submit></batch_submit>
    <batch_redirect></batch_redirect>
    <batch_directive></batch_directive>
    <directives>
      <directive name=""></directive>
    </directives>
  </batch_system>

   <batch_system type="cobalt" version="x.y">
     <batch_query>qstat</batch_query>
     <batch_submit>qsub</batch_submit>
     <batch_directive></batch_directive>
     <jobid_pattern>(\d+)</jobid_pattern>
     <depend_string> --dependencies</depend_string>
    <walltime_format>%H:%M:%s</walltime_format>
     <submit_args>
       <arg flag="--cwd" name="CASEROOT"/>
       <arg flag="-A" name="PROJECT"/>
       <arg flag="-t" name="JOB_WALLCLOCK_TIME"/>
       <!-- space required at beginning of name -->
       <arg flag="-n" name=" $TOTALPES/$PES_PER_NODE"/>
       <arg flag="-q" name="JOB_QUEUE"/>
       <arg flag="--mode script"/>
       <arg flag="--env" name='"CIMEROOT=$CIMEROOT"'/>
      </submit_args>
   </batch_system>

  <batch_system type="lsf" version="9.1">
    <batch_query args=" -w" >bjobs</batch_query>
    <batch_submit>bsub</batch_submit>
    <batch_redirect>&lt;</batch_redirect>
    <batch_directive>#BSUB</batch_directive>
    <jobid_pattern>&lt;(\d+)&gt;</jobid_pattern>
    <depend_pattern>^\#BSUB\s+-w.+\((\d+)\)</depend_pattern>
    <depend_string> -w 'done(jobid)'</depend_string>
    <walltime_format>%H:%M</walltime_format>
    <submit_args>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="-W" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-P" name="$PROJECT"/>
    </submit_args>
    <directives>
      <directive                       > -n {{ totaltasks }} </directive>
      <directive                       > -R "span[ptile={{ ptile }}]"</directive>
      <directive                       > -N  </directive>
      <directive default="poe"         > -a {{ poe }} </directive>
      <directive default="cesm.stdout" > -o {{ output_error_path }}.%J  </directive>
      <directive default="cesm.stderr" > -e {{ output_error_path }}.%J  </directive>
      <directive                       > -J {{ job_id }} </directive>
    </directives>
  </batch_system>

  <batch_system type="pbs" version="x.y">
    <batch_query args="-f" >qstat</batch_query>
    <batch_submit>qsub </batch_submit>
    <batch_directive>#PBS</batch_directive>
    <jobid_pattern>^(\d+)\.</jobid_pattern>
    <depend_string> -W depend=afterok:jobid</depend_string>
    <walltime_format>%H:%M:%S</walltime_format>
    <submit_args>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="-l walltime=" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-A" name="$PROJECT"/>
    </submit_args>
    <directives>
      <directive> -N {{ job_id }}</directive>
      <directive default="n"> -r {{ rerunnable }} </directive>
      <!-- <directive> -j oe {{ output_error_path }} </directive> -->
      <directive> -j oe </directive>
      <directive default="ae"  > -m {{ mail_options }} </directive>
      <directive> -V </directive>
    </directives>
  </batch_system>

   <batch_system type="slurm" version="x.y">
     <batch_query>squeue</batch_query>
     <batch_submit>sbatch</batch_submit>
     <batch_directive>#SBATCH</batch_directive>
     <jobid_pattern>(\d+)$</jobid_pattern>
     <depend_string> --dependency=afterok:jobid</depend_string>
    <walltime_format>%H:%M:%S</walltime_format>
     <submit_args>
       <arg flag="--time" name="$JOB_WALLCLOCK_TIME"/>
       <arg flag="-p" name="$JOB_QUEUE"/>
       <arg flag="--account" name="$PROJECT"/>
     </submit_args>
     <directives>
       <directive> --job-name={{ job_id }}</directive>
       <directive> --nodes={{ num_nodes }}</directive>
       <directive> --ntasks-per-node={{ tasks_per_node }}</directive>
       <directive> --output={{ output_error_path }}   </directive>
       <directive> --exclusive                        </directive>
     </directives>
   </batch_system>

  <!-- babbage is PBS -->
  <batch_system MACH="babbage" type="pbs">
    <directives>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
  </batch_system>

  <!-- babbageKnc is PBS -->
  <batch_system MACH="babbageKnc" type="pbs">
    <directives>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
  </batch_system>

  <!-- brutus is PBS -->
  <batch_system type="pbs" MACH="brutus" >
    <directives>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
      <queues>
	<queue walltimemax="00:59:00" jobmin="1" jobmax="9999" default="true">batch</queue>
      </queues>
      <walltimes>
	<walltime default="true">00:59:00</walltime>
      </walltimes>
  </batch_system>

  <!-- bluewaters is PBS -->
  <batch_system MACH="bluewaters" type="pbs" version="x.y">
    <directives>
      <directive>-l nodes={{ num_nodes }}:ppn={{ tasks_per_node }}:xe</directive>
      <directive default="/bin/bash" > -S {{ shell }} </directive>
    </directives>
      <queues>
        <queue walltimemax="24:00:00" default="true">regular</queue>
	<queue walltimemax="00:30:00" jobmin="1" jobmax="512">debug</queue>
      </queues>
      <walltimes>
	<walltime default="true">00:30:00</walltime>
	<walltime ccsm_estcost="1">01:00:00</walltime>
	<walltime ccsm_estcost="3">05:00:00</walltime>
      </walltimes>
   </batch_system>

  <!-- brutus is PBS -->
  <batch_system MACH="brutus" type="pbs">
    <directives>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
  </batch_system>

  <!-- eos is PBS -->
  <batch_system MACH="eos" type="pbs">
    <jobid_pattern>^(\d+)</jobid_pattern>
    <directives>
      <directive>-A $PROJECT</directive>
      <directive>-l mppwidth={{ mppwidth }}</directive>
      <directive>-l  nodes={{ num_nodes }}</directive>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
  </batch_system>

  <!-- erebus is PBS -->
  <batch_system MACH="erebus" type="pbs">
    <directives>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
  </batch_system>

   <!-- gaea is PBS -->
   <batch_system MACH="gaea" type="pbs" version="x.y">
     <directives>
       <directive>-A cpo</directive>
       <directive>-l {{ partition }}</directive>
       <directive>-l size={{ mppsize }}</directive>
       <directive>-E </directive>
       <directive>-d $RUNDIR</directive>
       <directive>-o $RUNDIR/$CASE.out </directive>
       <directive>-S /bin/bash  </directive>
     </directives>
     <queues>
       <queue walltimemax="01:00:00" jobmin="1" jobmax="860">debug</queue>
       <queue walltimemax="24:00:00" jobmin="861" jobmax="99999" default="true">batch</queue>
     </queues>
     <walltimes>
       <walltime default="true">00:45:00</walltime>
       <walltime ccsm_estcost="1">01:50:00</walltime>
       <walltime ccsm_estcost="3">05:00:00</walltime>
     </walltimes>
   </batch_system>

  <!-- hobart is PBS -->
  <batch_system type="pbs" MACH="hobart" version="x.y">
    <directives>
      <directive>-l nodes={{ num_nodes }}:ppn={{ tasks_per_node }}</directive>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
    <queues>
      <queue walltimemax="02:00:00" jobmin="1" jobmax="192" default="true">short</queue>
      <queue walltimemax="40:00:00" jobmin="1" jobmax="144" >long</queue>
    </queues>
  </batch_system>

   <!-- hera is SLURM -->
   <batch_system MACH="hera" type="slurm">
   <batch_directive>#MSUB</batch_directive>
   <directives>
     <directive>-A ees</directive>
     <directive>-l gres=lscratchd</directive>
   </directives>
   </batch_system>

  <batch_system MACH="mira" type="cobalt">
    <queues>
      <queue walltimemax="06:00:00" jobmin="1" jobmax="786432" default="true">default</queue>
    </queues>
    <walltimes>
      <walltime default="true">01:00:00</walltime>
      <walltime ccsm_estcost="-3">01:00:00</walltime>
      <walltime ccsm_estcost="0">01:00:00</walltime>
    </walltimes>
  </batch_system>

  <batch_system MACH="olympus" type="slurm">
    <queues>
      <queue walltimemin="0" walltimemax="00:59:00" jobmin="0" jobmax="9999" default="true">queue</queue>
    </queues>
    <walltimes>
      <walltime default="true">00:59:00</walltime>
      <walltime ccsm_estcost="2" >08:59:00</walltime>
    </walltimes>
    </batch_system>



  <!-- all pleiades machines are PBS -->
  <batch_system type="pbs" MACH="pleiades-has" version="x.y">
    <jobid_pattern>^(\S+)</jobid_pattern>
    <directives>
      <directive>-W group_list=$PROJECT </directive>
      <directive>-l select={{ num_nodes }}:ncpus=$MAX_TASKS_PER_NODE:mpiprocs={{ tasks_per_node }}:ompthreads={{ thread_count }}:model=has</directive>
      <directive>-l place=scatter:excl</directive>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
    <queues>
      <queue walltimemin="" walltimemax="" jobmin="0" jobmax="9999" default="true">normal</queue>
    </queues>
    <walltimes>
      <walltime default="true">08:00:00</walltime>
    </walltimes>
  </batch_system>

  <!-- all pleiades machines are PBS -->
  <batch_system type="pbs" MACH="pleiades-ivy" version="x.y">
    <jobid_pattern>^(\S+)</jobid_pattern>
    <directives>
      <directive>-W group_list=$PROJECT </directive>
      <directive>-l select={{ num_nodes }}:ncpus=$MAX_TASKS_PER_NODE:mpiprocs={{ tasks_per_node }}:ompthreads={{ thread_count }}:model=ivy</directive>
      <directive>-l place=scatter:excl</directive>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
    <queues>
      <queue walltimemin="" walltimemax="" jobmin="0" jobmax="9999" default="true">normal</queue>
    </queues>
    <walltimes>
      <walltime default="true">08:00:00</walltime>
    </walltimes>
  </batch_system>

  <batch_system MACH="skybridge" type="slurm" version="x.y">
    <queues>
      <queue jobmin="1" jobmax="480" default="true">ec</queue>
    </queues>
    <walltimes>
      <walltime default="true">0:50:00</walltime>
      <walltime ccsm_estcost="0">1:50:00</walltime>
      <walltime ccsm_estcost="1">5:00:00</walltime>
    </walltimes>
  </batch_system>

  <!-- all pleiades machines are PBS -->
  <batch_system type="pbs" MACH="pleiades-san" version="x.y">
    <jobid_pattern>^(\S+)</jobid_pattern>
    <directives>
      <directive>-W group_list=$PROJECT </directive>
      <directive>-l select={{ num_nodes }}:ncpus=$MAX_TASKS_PER_NODE:mpiprocs={{ tasks_per_node }}:ompthreads={{ thread_count }}:model=san</directive>
      <directive>-l place=scatter:excl</directive>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
    <queues>
      <queue walltimemin="" walltimemax="" jobmin="0" jobmax="9999" default="true">normal</queue>
    </queues>
    <walltimes>
      <walltime default="true">08:00:00</walltime>
    </walltimes>
  </batch_system>

  <!-- all pleiades machines are PBS -->
  <batch_system MACH="pleiades-wes" version="x.y" type="pbs">
    <jobid_pattern>^(\S+)</jobid_pattern>
    <directives>
      <directive>-W group_list=$PROJECT </directive>
      <directive>-l select={{ num_nodes }}:ncpus=$MAX_TASKS_PER_NODE:mpiprocs={{ tasks_per_node }}:ompthreads={{ thread_count }}:model=wes</directive>
      <directive>-l place=scatter:excl</directive>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
  </batch_system>

  <!-- sierra is SLURM -->
   <batch_system MACH="sierra" type="slurm">
   <batch_directive>#MSUB</batch_directive>
   <directives>
     <directive> </directive>
     <directive>-A ees </directive>
     <directive>-l nodes={{ num_nodes }}</directive>
     <directive>-l gres=lscratchd</directive>
   </directives>
   </batch_system>

   <batch_system MACH="eastwind" type="slurm" version="x.y">
     <queues>
       <queue jobmin="1" jobmax="9999" default="true">batch</queue>
     </queues>
     <walltimes>
       <walltime default="true">0:59:00</walltime>
     </walltimes>
   </batch_system>

   <batch_system MACH="corip1" type="slurm" version="x.y">
     <queues>
       <queue walltimemax="06:00:00" jobmin="1" jobmax="45440">regular</queue>
       <queue walltimemax="00:30:00" jobmin="1" jobmax="3072" default="true">debug</queue>
     </queues>
     <walltimes>
       <walltime default="true">00:30:00</walltime>
     </walltimes>
   </batch_system>

   <batch_system MACH="edison" type="slurm" version="x.y">
     <queues>
       <queue walltimemax="36:00:00" jobmin="1" jobmax="130181" >regular</queue>
       <queue walltimemax="00:30:00" jobmin="1" jobmax="12288" default="true">debug</queue>
     </queues>
     <walltimes>
       <walltime default="true">00:30:00</walltime>
     </walltimes>
   </batch_system>

   <batch_system MACH="stampede" type="slurm" version="x.y">
     <queues>
       <queue walltimemax="48:00:00" jobmin="1" jobmax="4096" >normal</queue>
       <queue walltimemax="02:00:00" jobmin="1" jobmax="256" default="true">development</queue>
     </queues>
     <walltimes>
       <walltime default="true">00:30:00</walltime>
     </walltimes>
   </batch_system>

   <batch_system MACH="rosa" type="slurm" version="x.y">
     <queues>
       <queue default="true">default</queue>
     </queues>
     <walltimes>
       <walltime default="true">01:30:00</walltime>
     </walltimes>
   </batch_system>

  <!-- titan is PBS -->
  <batch_system MACH="titan" type="pbs">
    <directives>
      <directive default="/bin/bash" > -S {{ shell }}  </directive>
    </directives>
  </batch_system>

  <batch_system type="slurm" MACH="constance" version="x.y">
    <walltimes>
      <walltime default="true">00:59:00</walltime>
      <walltime ccsm_estcost="2" >04:59:00</walltime>
    </walltimes>
  </batch_system>

  <batch_system MACH="yellowstone" type="lsf" version="9.1">
    <queues>
      <queue walltimemax="24:00" jobmin="1" jobmax="1" jobname="case.lt_archive">hpss</queue>
      <queue walltimemax="24:00" jobmin="1" jobmax="8" >caldera</queue>
      <queue walltimemax="12:00" jobmin="9" jobmax="16384" default="true">regular</queue>
      <queue walltimemax="12:00" jobmin="16385" jobmax="65536">capability</queue>
    </queues>
    <walltimes>
      <walltime default="true">2:00</walltime>
      <walltime ccsm_estcost="-1">2:00</walltime>
      <walltime ccsm_estcost="0">4:00</walltime>
      <walltime ccsm_estcost="1">12:00</walltime>
    </walltimes>
  </batch_system>

  <batch_jobs>
    <!-- order matters, with no-batch jobs will be run in the order listed here -->
    <job name="case.run">
      <template>template.case.run</template>
      <task_count>default</task_count>
      <prereq>$BUILD_COMPLETE and not $TEST</prereq>
    </job>
   <job name="case.test">
      <template>template.case.test</template>
      <task_count>default</task_count>
      <prereq>$BUILD_COMPLETE and $TEST</prereq>
    </job>
    <job name="case.st_archive">
      <template>template.st_archive</template>
      <task_count>1</task_count>
      <!-- If DOUT_S is true and case.run (or case.test) exits successfully then run st_archive-->
      <dependency>case.run or case.test</dependency>
      <prereq>$DOUT_S</prereq>
    </job>
    <job name="case.lt_archive">
      <template>template.lt_archive</template>
      <task_count>1</task_count>
      <dependency>case.st_archive</dependency>
      <prereq>$DOUT_L_MS</prereq>
    </job>
  </batch_jobs>


</config_batch>


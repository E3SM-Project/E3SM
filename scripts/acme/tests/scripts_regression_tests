#!/usr/bin/env python

import unittest, sys, os, tempfile, shutil, re, threading, time, signal, glob, stat

SCRIPT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(SCRIPT_DIR)
from acme_util import run_cmd
import acme_util

DART_CONFIG = "DartConfiguration.tcl"
DART_BACKUP = "temp_dart_backup"

###############################################################################
class RunUnitTests(unittest.TestCase):
###############################################################################

    def do_unit_tests(self, script):
        stat, output, _ = run_cmd("./%s --test 2>&1" % script, ok_to_fail=True, from_dir=SCRIPT_DIR)
        self.assertEqual(stat, 0, msg=output)

    def test_acme_bisect_unit_test(self):
        self.do_unit_tests("acme_bisect")

    def test_cime_merge_helper_unit_test(self):
        self.do_unit_tests("cime_merge_helper")

    def test_compare_namelists_unit_test(self):
        self.do_unit_tests("compare_namelists")

    def test_jenkins_generic_job_unit_test(self):
        self.do_unit_tests("jenkins_generic_job")

    def test_simple_compare_unit_test(self):
        self.do_unit_tests("simple_compare")

    def test_update_acme_tests_unit_test(self):
        self.do_unit_tests("update_acme_tests")

    def test_wait_for_tests_unit_test(self):
        self.do_unit_tests("wait_for_tests")

###############################################################################
def make_fake_teststatus(path, testname, status):
###############################################################################
    fd = open(path, "w")
    fd.write("%s %s\n" % (status, testname))
    fd.close()

###############################################################################
def parse_test_status(line):
###############################################################################
    regex = re.compile(r"Test '(\w+)' finished with status '(\w+)'")
    m = regex.match(line)
    return m.groups()

###############################################################################
def kill_subprocesses(name=None, sig=signal.SIGKILL, expected_num_killed=None, tester=None):
###############################################################################
    # Kill all subprocesses
    proc_ids = acme_util.find_proc_id(proc_name=name, children_only=True)
    if (expected_num_killed is not None):
        tester.assertEqual(len(proc_ids), expected_num_killed,
                           msg="Expected to find %d processes to kill, found %d" % (expected_num_killed, len(proc_ids)))
    for proc_id in proc_ids:
        try:
            os.kill(proc_id, sig)
        except OSError:
            pass

###############################################################################
def kill_python_subprocesses(sig=signal.SIGKILL, expected_num_killed=None, tester=None):
###############################################################################
    kill_subprocesses("[Pp]ython", sig, expected_num_killed, tester)

###############################################################################
def setup_proxy():
###############################################################################
    if ("http_proxy" not in os.environ):
        machine = acme_util.probe_machine_name()
        if (machine is not None):
            proxy = acme_util.get_machine_info(machine)[6]
            if (proxy is not None):
                os.environ["http_proxy"] = proxy
                return True

    return False

###############################################################################
class TestWaitForTests(unittest.TestCase):
###############################################################################

    ###########################################################################
    def setUp(self):
    ###########################################################################
        self._testdir_all_pass     = tempfile.mkdtemp()
        self._testdir_with_fail    = tempfile.mkdtemp()
        self._testdir_unfinished   = tempfile.mkdtemp()

        for r in range(10):
            make_fake_teststatus(os.path.join(self._testdir_all_pass, "TestStatus_%d" % r), "Test_%d" % r, "PASS")

        for r in range(10):
            make_fake_teststatus(os.path.join(self._testdir_with_fail, "TestStatus_%d" % r), "Test_%d" % r, "PASS" if r % 2 == 0 else "FAIL")

        for r in range(10):
            make_fake_teststatus(os.path.join(self._testdir_unfinished, "TestStatus_%d" % r), "Test_%d" % r, "RUN" if r == 5 else "PASS")

        # Set up proxy if possible
        self._unset_proxy = setup_proxy()

        self._thread_error = None

        # wait_for_tests could blow away our dart config, need to back it up
        if (os.path.exists(DART_CONFIG)):
            shutil.move(DART_CONFIG, DART_BACKUP)

    ###########################################################################
    def tearDown(self):
    ###########################################################################
        shutil.rmtree(self._testdir_all_pass)
        shutil.rmtree(self._testdir_with_fail)
        shutil.rmtree(self._testdir_unfinished)

        kill_subprocesses()

        if (self._unset_proxy):
            del os.environ["http_proxy"]

        if (os.path.exists(DART_BACKUP)):
            shutil.move(DART_BACKUP, DART_CONFIG)

    ###########################################################################
    def simple_test(self, testdir, expected_results, extra_args=""):
    ###########################################################################
        try:
            stat, output, errput = run_cmd("%s/wait_for_tests -p ACME_test TestStatus* %s" % (SCRIPT_DIR, extra_args), ok_to_fail=True, from_dir=testdir)
            if (expected_results == ["PASS"]*len(expected_results)):
                self.assertEqual(stat, 0, msg="wait_for_tests output:\n%s\n\nerrput:\n%s" % (output, errput))
            else:
                self.assertNotEqual(stat, 0, msg="wait_for_tests output:\n%s\n\nerrput:\n%s" % (output, errput))

            lines = [line for line in output.splitlines() if line.startswith("Test '")]
            self.assertEqual(len(lines), 10)
            for idx, line in enumerate(lines):
                testname, status = parse_test_status(line)
                self.assertEqual(status, expected_results[idx])
                self.assertEqual(testname, "Test_%d" % idx)

        except AssertionError as e:
            self._thread_error = str(e)

    ###########################################################################
    def test_wait_for_test_all_pass(self):
    ###########################################################################
        self.simple_test(self._testdir_all_pass, ["PASS"] * 10)

    ###########################################################################
    def test_wait_for_test_with_fail(self):
    ###########################################################################
        expected_results = ["PASS" if item % 2 == 0 else "FAIL" for item in range(10)]
        self.simple_test(self._testdir_with_fail, expected_results)

    ###########################################################################
    def test_wait_for_test_no_wait(self):
    ###########################################################################
        expected_results = ["RUN" if item == 5 else "PASS" for item in range(10)]
        self.simple_test(self._testdir_unfinished, expected_results, "-n")

    ###########################################################################
    def test_wait_for_test_wait(self):
    ###########################################################################
        run_thread = threading.Thread(target=self.simple_test, args=(self._testdir_unfinished, ["PASS"] * 10))
        run_thread.daemon = True
        run_thread.start()

        time.sleep(5) # Kinda hacky

        self.assertTrue(run_thread.isAlive(), msg="wait_for_tests should have waited")

        make_fake_teststatus(os.path.join(self._testdir_unfinished, "TestStatus_5"), "Test_5", "PASS")

        run_thread.join(timeout=30)

        self.assertFalse(run_thread.isAlive(), msg="wait_for_tests should have finished")

        self.assertTrue(self._thread_error is None, msg="Thread had failure: %s" % self._thread_error)

    ###########################################################################
    def test_wait_for_test_wait_kill(self):
    ###########################################################################
        expected_results = ["RUN" if item == 5 else "PASS" for item in range(10)]
        run_thread = threading.Thread(target=self.simple_test, args=(self._testdir_unfinished, expected_results))
        run_thread.daemon = True
        run_thread.start()

        time.sleep(5)

        self.assertTrue(run_thread.isAlive(), msg="wait_for_tests should have waited")

        kill_python_subprocesses(signal.SIGTERM, expected_num_killed=1, tester=self)

        run_thread.join(timeout=30)

        self.assertFalse(run_thread.isAlive(), msg="wait_for_tests should have finished")

        self.assertTrue(self._thread_error is None, msg="Thread had failure: %s" % self._thread_error)

    ###########################################################################
    def test_wait_for_test_cdash_pass(self):
    ###########################################################################
        expected_results = ["PASS"] * 10
        run_thread = threading.Thread(target=self.simple_test, args=(self._testdir_all_pass, expected_results, "-d regression_test_pass"))
        run_thread.daemon = True
        run_thread.start()

        run_thread.join(timeout=30)

        self.assertFalse(run_thread.isAlive(), msg="wait_for_tests should have finished")

        self.assertTrue(self._thread_error is None, msg="Thread had failure: %s" % self._thread_error)

    ###########################################################################
    def test_wait_for_test_cdash_kill(self):
    ###########################################################################
        expected_results = ["RUN" if item == 5 else "PASS" for item in range(10)]
        run_thread = threading.Thread(target=self.simple_test, args=(self._testdir_unfinished, expected_results, "-d regression_test_kill"))
        run_thread.daemon = True
        run_thread.start()

        time.sleep(5)

        self.assertTrue(run_thread.isAlive(), msg="wait_for_tests should have waited")

        kill_python_subprocesses(signal.SIGTERM, expected_num_killed=1, tester=self)

        run_thread.join(timeout=30)

        self.assertFalse(run_thread.isAlive(), msg="wait_for_tests should have finished")

        self.assertTrue(self._thread_error is None, msg="Thread had failure: %s" % self._thread_error)

        cdash_result_dir = os.path.join(self._testdir_unfinished, "Testing")
        tag_file         = os.path.join(cdash_result_dir, "TAG")
        self.assertTrue(os.path.isdir(cdash_result_dir))
        self.assertTrue(os.path.isfile(tag_file))

        tag = open(tag_file, "r").readlines()[0].strip()
        xml_file = os.path.join(cdash_result_dir, tag, "Test.xml")
        self.assertTrue(os.path.isfile(xml_file))

        xml_contents = open(xml_file, "r").read()
        self.assertTrue(r'<TestList><Test>Test_0</Test><Test>Test_1</Test><Test>Test_2</Test><Test>Test_3</Test><Test>Test_4</Test><Test>Test_5</Test><Test>Test_6</Test><Test>Test_7</Test><Test>Test_8</Test><Test>Test_9</Test></TestList>'
                        in xml_contents)
        self.assertTrue(r'<Test Status="failed"><Name>Test_5</Name>' in xml_contents)

        # TODO: Any further checking of xml output worth doing?

###############################################################################
class TestJenkinsGenericJob(unittest.TestCase):
###############################################################################

    ###########################################################################
    def setUp(self):
    ###########################################################################
        self._thread_error      = None
        self._wget_file         = tempfile.mktemp()
        self._unset_proxy       = setup_proxy()
        self._baseline_name     = "fake_testing_only_%s" % acme_util.get_utc_timestamp()

        # wait_for_tests could blow away our dart config, need to back it up
        if (os.path.exists(DART_CONFIG)):
            shutil.move(DART_CONFIG, DART_BACKUP)

    ###########################################################################
    def tearDown(self):
    ###########################################################################
        kill_subprocesses()

        if (os.path.isfile(self._wget_file)):
            os.remove(self._wget_file)

        if (self._unset_proxy):
            del os.environ["http_proxy"]

        baseline_area = acme_util.get_machine_info()[5]
        baselines = os.path.join(baseline_area, self._baseline_name)
        if (os.path.isdir(baselines)):
            shutil.rmtree(baselines)

        if (os.path.exists(DART_BACKUP)):
            shutil.move(DART_BACKUP, DART_CONFIG)

    ###########################################################################
    def simple_test(self, expect_works, extra_args):
    ###########################################################################
        try:
            stat, output, errput = run_cmd("%s/jenkins_generic_job -t acme_tiny %s" % (SCRIPT_DIR, extra_args), ok_to_fail=True)
            if (expect_works):
                self.assertEqual(stat, 0, msg="jenkins_generic_job output:\n%s\n\nerrput:\n%s" % (output, errput))
            else:
                self.assertNotEqual(stat, 0, msg="jenkins_generic_job output:\n%s\n\nerrput:\n%s" % (output, errput))

        except AssertionError as e:
            self._thread_error = str(e)

    ###########################################################################
    def assert_dashboard_has_build(self, build_name):
    ###########################################################################
        time.sleep(10) # Give chance for cdash to update

        run_cmd("wget http://my.cdash.org/index.php?project=ACME_test -O %s" % self._wget_file)

        stat = run_cmd("grep %s %s" % (build_name, self._wget_file), ok_to_fail=True)[0]
        self.assertEqual(stat, 0, msg="Dashboard did not have build '%s'" % build_name)

    ###########################################################################
    def assert_no_sentinel(self):
    ###########################################################################
        testroot = acme_util.get_machine_info()[4]
        self.assertFalse(os.path.isfile(os.path.join(testroot, "ONGOING_TEST")),
                         "job did not cleanup successfully")

    ###########################################################################
    def test_jenkins_generic_job(self):
    ###########################################################################
        # Unfortunately, this test is very long-running

        build_name = "jenkins_generic_job_pass_%s" % acme_util.get_utc_timestamp()
        self.simple_test(True, "-p ACME_test --branch master -d -c %s" % build_name)

        self.assert_no_sentinel()
        self.assert_dashboard_has_build(build_name)
        self.assertTrue(self._thread_error is None, msg="Thread had failure: %s" % self._thread_error)

    ###########################################################################
    def test_jenkins_generic_job_kill(self):
    ###########################################################################
        build_name = "jenkins_generic_job_kill_%s" % acme_util.get_utc_timestamp()
        run_thread = threading.Thread(target=self.simple_test, args=(False, "-p ACME_test --branch master -d -c %s" % build_name))
        run_thread.daemon = True
        run_thread.start()

        time.sleep(60)

        kill_subprocesses(sig=signal.SIGTERM)

        run_thread.join(timeout=30)

        self.assertFalse(run_thread.isAlive(), msg="jenkins_generic_job should have finished")
        self.assert_no_sentinel()
        self.assert_dashboard_has_build(build_name)
        self.assertTrue(self._thread_error is None, msg="Thread had failure: %s" % self._thread_error)

    ###############################################################################
    def test_jenkins_generic_job_rebless_namelist(self):
    ###############################################################################
        # Generate some namelist baselines
        self.simple_test(True, "-g -n --branch %s" % self._baseline_name)

        # Basic namelist compare
        self.simple_test(True, "-n --branch %s" % self._baseline_name)

        # Modify namelist
        fake_nl = """
 &fake_nml
   fake_item = 'fake'
   fake = .true.
/"""
        baseline_area = acme_util.get_machine_info()[5]
        baseline_glob = glob.glob(os.path.join(baseline_area, self._baseline_name, "ERS*"))
        self.assertEqual(len(baseline_glob), 1, msg="Expected one match, got:\n%s" % "\n".join(baseline_glob))

        baseline_dir = baseline_glob[0]
        nl_path = os.path.join(baseline_dir, "CaseDocs", "datm_in")
        self.assertTrue(os.path.isfile(nl_path), msg="Missing file %s" % nl_path)

        import stat
        os.chmod(nl_path, stat.S_IRUSR | stat.S_IWUSR)
        nl_file = open(nl_path, "a")
        nl_file.write(fake_nl)
        nl_file.close()

        # Basic namelist compare should now fail
        self.simple_test(False, "-n --branch %s" % self._baseline_name)

        # Bless
        stat, output, errput = run_cmd("%s/bless_test_results -n -f -b %s" % (SCRIPT_DIR, self._baseline_name), ok_to_fail=True)
        self.assertEqual(stat, 0, msg="bless_test_results output:\n%s\n\nerrput:\n%s" % (output, errput))

        # Basic namelist compare should now pass again
        self.simple_test(True, "-n --branch %s" % self._baseline_name)

###########################################################################

if (__name__ == "__main__"):
    unittest.main()

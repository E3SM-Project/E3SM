#!/bin/tcsh 
#
#  This script will configure, build and run HOMME using the
#  Jablownowski and Williamson baroclinic instability test case
#  configured as the dycore is used in E3SM v1
#
#  72 levels
#  40 tracers
#    
#  ne4  ultra-low-res for testing
#  ne30 (1 degree) 
#  ne120 (1/4 degree)
#
#
#
#SBATCH --job-name v1bench
#SBATCH -N 1
#SBATCH -C knl
#SBATCH --time=0:15:00
#SBATCH -p debug
#SBATCH -A acme

#
#  set paths to source code, build directory and run directory
#
set wdir =  ~/scratch2/knl/v1bench           # run directory
set HOMME = `pwd`/../../..               # /path/to/acme/components/homme
set MACH = $HOMME/cmake/machineFiles/cori-knl.cmake

#
#  Which problem?  tiny, ne30 or ne120 configuration
#

# TINY FOR TESTING
set namelist = v1-tiny.nl ; set name = tiny      
# use 4 nodes

# NE30
# good nodes: 338  169    85  43    22  11  6
# elem/node    16   32    64  128 
#set namelist = v1-ne30.nl  ; set name = ne30

# NE120
# good nodes:  5400 2700 1350  675  338      225  169      85          43          22
# ele/node       16   32   64  128  256/255  384  512/511  1024/1023  2048/2047   4096/4095
#set namelist = v1-ne120.nl ; set name = ne120



    
#
#  mpi run command
#
setenv OMP_STACKSIZE 16M     #  Cori has 96GB per node. had to lower to 8M on 3K nodes
setenv PER_NODE  64          #  MPI per node
setenv OMP_NUM_THREADS 2
#setenv OMP_NUM_THREADS 1

# number of virtual cores per MPI task
set VC_PER_MPI = 256  # Set this to 272 if using PER_NODE divides 272 instead of 256
@ VC_PER_MPI /= $PER_NODE

setenv KMP_AFFINITY granularity=core,scatter
set bind = --cpu_bind=core
#setenv KMP_AFFINITY granularity=thread,scatter
#set bind = --cpu_bind=thread

# compute number of MPI tasks
if (! ${?SLURM_NNODES} ) then 
  # not running in batch system.  set some defaults so this script
  # will work on a workstation
  set SLURM_NNODES=1
  set PER_NODE=64
endif
set NNODES =  $SLURM_NNODES

if ($#argv >= 1) then
   # override number of nodes with $1
   set NNODES =  $1
endif

set NMPI = $NNODES
@ NMPI *= $PER_NODE
if ( $NMPI > 393216 ) set NMPI = 393216  # max number of elements in NE=256 mesh


echo NODES =            $NNODES
echo NMPI_PER_NODE =    $PER_NODE
echo NTHREADS_PER_MPI = $OMP_NUM_THREADS
# note: in tests on 4K nodes,the --bcase and --compress options were much slower. DONT USE:
#set mpirun = "srun --bcast=/tmp/${SLURM_JOB_ID} --compress=lz4 -n $NMPI -N $NNODES -c $VC_PER_MPI $bind"
set mpirun = "srun -n $NMPI -N $NNODES -c $VC_PER_MPI $bind"
echo mpi commnand:
echo $mpirun


set input = $HOMME/test/benchmarks/v1  # input files for test case
set vdir = $HOMME/test/vcoord            # vertical coordinate files
set bld = $wdir/bld
set run = $wdir/run-$NNODES-$OMP_NUM_THREADS-$$
set nlev = 72
set qsize = 40

#
#  BUILD PREQX
#  rm $bld/CMakeCache.txt to force re-configure
#
module unload craype-haswell ; module load craype-mic-knl

mkdir -p $bld
cd $bld
set exe = $bld/src/preqx/preqx
set build = 1  # set to 1 to force build
# rm $bld/CMakeCache.txt    # remove this file to force re-configure
if (! -f CMakeCache.txt) then
   rm -rf CMakeFiles CMakeCache.txt src
   echo "running CMAKE to configure the model"

   cmake -C $MACH -DQSIZE_D=$qsize -DPREQX_PLEV=$nlev -DPREQX_NP=4  \
   -DBUILD_HOMME_SWEQX=FALSE  -DPREQX_USE_PIO=TRUE     \
   -DPREQX_USE_ENERGY=FALSE  $HOMME

   if ($status) exit
   make -j4 clean
endif
if ( ! -f $exe) then
   make -j4 preqx
   if ($status) exit
endif

#
#  Run the code
#
mkdir -p $run/movies
cd $run


# default: assume pure sigma levels:
set vfile_mid     = "./acme-72m.ascii"
set vfile_int     = "./acme-72i.ascii"

# copy all vertical levels to run directory
rsync -a  $vdir/acme-72?.ascii  $run   

# namelist has to be called input.nl for perf settings to be read
\rm -f input.nl
\cp -f $input/$namelist input.nl

date
$mpirun $exe  < input.nl
date

if (-f  HommeTime  ) then
   # save timings from run
   set timingfile = $name.nodes${NNODES}.HommeTime
   set summary    = $name.nodes${NNODES}.summary
   mv HommeTime $timingfile
   # total run time (not counting init)
   grep -a prim_main_loop $timingfile | head -1 | tee $summary

   # breakdown dyn, tracers, remap.  about 97% of the cost:
   grep -a prim_step_dyn  $timingfile | head -1 | tee -a $summary
   grep -a PAT_remap      $timingfile | head -1 | tee -a $summary
   grep -a vertical_remap $timingfile | head -1 | tee -a $summary
   echo "run parameters:" >> $summary
   cat input.nl >> $summary
endif

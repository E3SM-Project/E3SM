<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.13.2" xml:lang="en-US">
  <compounddef id="libtorch__backend_8cpp" kind="file" language="C++">
    <compoundname>libtorch_backend.cpp</compoundname>
    <includes refid="libtorch__backend_8hpp" local="yes">libtorch_backend.hpp</includes>
    <includes local="no">iostream</includes>
    <includes local="no">torch/script.h</includes>
    <includes local="no">torch/torch.h</includes>
    <incdepgraph>
      <node id="3">
        <label>inference_backend.hpp</label>
        <link refid="inference__backend_8hpp"/>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="5" relation="include">
        </childnode>
        <childnode refid="6" relation="include">
        </childnode>
      </node>
      <node id="1">
        <label>components/emulator_comps/common/src/inference/libtorch_backend.cpp</label>
        <link refid="libtorch__backend_8cpp"/>
        <childnode refid="2" relation="include">
        </childnode>
        <childnode refid="7" relation="include">
        </childnode>
        <childnode refid="8" relation="include">
        </childnode>
        <childnode refid="9" relation="include">
        </childnode>
      </node>
      <node id="2">
        <label>libtorch_backend.hpp</label>
        <link refid="libtorch__backend_8hpp"/>
        <childnode refid="3" relation="include">
        </childnode>
        <childnode refid="4" relation="include">
        </childnode>
        <childnode refid="5" relation="include">
        </childnode>
      </node>
      <node id="7">
        <label>iostream</label>
      </node>
      <node id="4">
        <label>memory</label>
      </node>
      <node id="5">
        <label>string</label>
      </node>
      <node id="8">
        <label>torch/script.h</label>
      </node>
      <node id="9">
        <label>torch/torch.h</label>
      </node>
      <node id="6">
        <label>vector</label>
      </node>
    </incdepgraph>
    <innerclass refid="structemulator_1_1inference_1_1LibTorchBackend_1_1Impl" prot="public">emulator::inference::LibTorchBackend::Impl</innerclass>
    <innernamespace refid="namespaceemulator">emulator</innernamespace>
    <innernamespace refid="namespaceemulator_1_1inference">emulator::inference</innernamespace>
    <briefdescription>
<para>LibTorch inference backend implementation. </para>
    </briefdescription>
    <detaileddescription>
<para>Provides native C++ neural network inference using LibTorch (PyTorch C++ API). This backend loads TorchScript models and executes inference without Python.</para>
<para><simplesect kind="note"><para>Models must be exported to TorchScript format (.pt) using torch.jit.trace() or torch.jit.script() before use with this backend.</para>
</simplesect>
<simplesect kind="see"><para>LibTorchBackend </para>
</simplesect>
</para>
    </detaileddescription>
    <programlisting>
<codeline lineno="1"><highlight class="normal"></highlight></codeline>
<codeline lineno="14"><highlight class="normal"></highlight></codeline>
<codeline lineno="15"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&quot;<ref refid="libtorch__backend_8hpp" kindref="compound">libtorch_backend.hpp</ref>&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="16"><highlight class="normal"></highlight></codeline>
<codeline lineno="17"><highlight class="normal"></highlight><highlight class="comment">//<sp/>Standard<sp/>library</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="18"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;iostream&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="19"><highlight class="normal"></highlight></codeline>
<codeline lineno="20"><highlight class="normal"></highlight><highlight class="comment">//<sp/>LibTorch<sp/>headers</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="21"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;torch/script.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="22"><highlight class="normal"></highlight><highlight class="preprocessor">#include<sp/>&lt;torch/torch.h&gt;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="23"><highlight class="normal"></highlight></codeline>
<codeline lineno="24"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal"><ref refid="namespaceemulator" kindref="compound">emulator</ref><sp/>{</highlight></codeline>
<codeline lineno="25"><highlight class="normal"></highlight><highlight class="keyword">namespace<sp/></highlight><highlight class="normal"><ref refid="namespaceemulator_1_1inference" kindref="compound">inference</ref><sp/>{</highlight></codeline>
<codeline lineno="26"><highlight class="normal"></highlight></codeline>
<codeline lineno="33" refid="structemulator_1_1inference_1_1LibTorchBackend_1_1Impl" refkind="compound"><highlight class="normal"></highlight><highlight class="keyword">struct<sp/></highlight><highlight class="normal"><ref refid="structemulator_1_1inference_1_1LibTorchBackend_1_1Impl" kindref="compound">LibTorchBackend::Impl</ref><sp/>{</highlight></codeline>
<codeline lineno="34"><highlight class="normal"><sp/><sp/>torch::jit::script::Module<sp/><ref refid="structemulator_1_1inference_1_1LibTorchBackend_1_1Impl_1a37394e633ac05cc9343eb71b36beb528" kindref="member">model</ref>;<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="35"><highlight class="normal"><sp/><sp/>torch::Device<sp/><ref refid="structemulator_1_1inference_1_1LibTorchBackend_1_1Impl_1a220f517f7c2fa1c69bdde4d6c84fa285" kindref="member">device</ref><sp/>=<sp/>torch::kCPU;<sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight></codeline>
<codeline lineno="36"><highlight class="normal"><sp/><sp/>torch::ScalarType<sp/><ref refid="structemulator_1_1inference_1_1LibTorchBackend_1_1Impl_1a913b6682cc12a62d32e38884818a4612" kindref="member">dtype</ref><sp/>=<sp/>torch::kFloat32;<sp/></highlight></codeline>
<codeline lineno="37"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/><ref refid="structemulator_1_1inference_1_1LibTorchBackend_1_1Impl_1ab02e6ea7ec7437533e54c52e213f3b53" kindref="member">model_loaded</ref><sp/>=<sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;<sp/></highlight></codeline>
<codeline lineno="38"><highlight class="normal">};</highlight></codeline>
<codeline lineno="39"><highlight class="normal"></highlight></codeline>
<codeline lineno="40"><highlight class="normal"><ref refid="classemulator_1_1inference_1_1LibTorchBackend_1a1c0da195cd923659f7dce02b14214cc1" kindref="member">LibTorchBackend::LibTorchBackend</ref>()<sp/>=<sp/></highlight><highlight class="keywordflow">default</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="41"><highlight class="normal"></highlight></codeline>
<codeline lineno="42"><highlight class="normal"><ref refid="classemulator_1_1inference_1_1LibTorchBackend_1a7ebb02a6447c00da5deb99c390607706" kindref="member">LibTorchBackend::~LibTorchBackend</ref>()<sp/>{</highlight></codeline>
<codeline lineno="43"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(m_initialized)<sp/>{</highlight></codeline>
<codeline lineno="44"><highlight class="normal"><sp/><sp/><sp/><sp/><ref refid="classemulator_1_1inference_1_1LibTorchBackend_1a8c849a1784ce1e351fdd2a6c5b86639f" kindref="member">finalize</ref>();</highlight></codeline>
<codeline lineno="45"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="46"><highlight class="normal">}</highlight></codeline>
<codeline lineno="47"><highlight class="normal"></highlight></codeline>
<codeline lineno="54"><highlight class="normal"></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/><ref refid="classemulator_1_1inference_1_1LibTorchBackend_1a748dcb4fd55a2b336c1de2bee87c3d85" kindref="member">LibTorchBackend::initialize</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>InferenceConfig<sp/>&amp;config)<sp/>{</highlight></codeline>
<codeline lineno="55"><highlight class="normal"><sp/><sp/>m_config<sp/>=<sp/>config;</highlight></codeline>
<codeline lineno="56"><highlight class="normal"><sp/><sp/>m_impl<sp/>=<sp/>std::make_unique&lt;Impl&gt;();</highlight></codeline>
<codeline lineno="57"><highlight class="normal"></highlight></codeline>
<codeline lineno="58"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Configure<sp/>execution<sp/>device</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="59"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(m_config.<ref refid="structemulator_1_1inference_1_1InferenceConfig_1abbde15ef4b44efb6558b8018ed003fd2" kindref="member">device_id</ref><sp/>&gt;=<sp/>0<sp/>&amp;&amp;<sp/>torch::cuda::is_available())<sp/>{</highlight></codeline>
<codeline lineno="60"><highlight class="normal"><sp/><sp/><sp/><sp/>m_impl-&gt;device<sp/>=<sp/>torch::Device(torch::kCUDA,<sp/>m_config.<ref refid="structemulator_1_1inference_1_1InferenceConfig_1abbde15ef4b44efb6558b8018ed003fd2" kindref="member">device_id</ref>);</highlight></codeline>
<codeline lineno="61"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="62"><highlight class="normal"><sp/><sp/><sp/><sp/>m_impl-&gt;device<sp/>=<sp/>torch::kCPU;</highlight></codeline>
<codeline lineno="63"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="64"><highlight class="normal"></highlight></codeline>
<codeline lineno="65"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Configure<sp/>precision</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="66"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Default<sp/>to<sp/>Float64<sp/>for<sp/>E3SM<sp/>compatibility<sp/>(E3SM<sp/>uses<sp/>double<sp/>precision)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="67"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>FP16<sp/>or<sp/>FP32<sp/>only<sp/>available/recommended<sp/>on<sp/>CUDA<sp/>for<sp/>acceleration</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="68"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(m_config.use_fp16<sp/>&amp;&amp;<sp/>m_impl-&gt;device.is_cuda())<sp/>{</highlight></codeline>
<codeline lineno="69"><highlight class="normal"><sp/><sp/><sp/><sp/>m_impl-&gt;dtype<sp/>=<sp/>torch::kFloat16;</highlight></codeline>
<codeline lineno="70"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="71"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Use<sp/>Float32<sp/>by<sp/>default</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="72"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>NOTE:<sp/>E3SM<sp/>uses<sp/>double<sp/>precision<sp/>by<sp/>default</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="73"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>make<sp/>this<sp/>configurable<sp/>if<sp/>needed</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="74"><highlight class="normal"><sp/><sp/><sp/><sp/>m_impl-&gt;dtype<sp/>=<sp/>torch::kFloat32;</highlight></codeline>
<codeline lineno="75"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="76"><highlight class="normal"></highlight></codeline>
<codeline lineno="77"><highlight class="normal"><sp/><sp/></highlight><highlight class="comment">//<sp/>Load<sp/>TorchScript<sp/>model</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="78"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">try</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="79"><highlight class="normal"><sp/><sp/><sp/><sp/>m_impl-&gt;model<sp/>=<sp/>torch::jit::load(m_config.model_path,<sp/>m_impl-&gt;device);</highlight></codeline>
<codeline lineno="80"><highlight class="normal"><sp/><sp/><sp/><sp/>m_impl-&gt;model.eval();<sp/></highlight><highlight class="comment">//<sp/>Set<sp/>to<sp/>evaluation<sp/>mode<sp/>(disables<sp/>dropout,<sp/>etc.)</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="81"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">catch</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>c10::Error<sp/>&amp;e)<sp/>{</highlight></codeline>
<codeline lineno="82"><highlight class="normal"><sp/><sp/><sp/><sp/>std::cerr<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;[LibTorchBackend]<sp/>Failed<sp/>to<sp/>load<sp/>model:<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>e.what()</highlight></codeline>
<codeline lineno="83"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&lt;&lt;<sp/>std::endl;</highlight></codeline>
<codeline lineno="84"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="85"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="86"><highlight class="normal"><sp/><sp/>m_impl-&gt;model_loaded<sp/>=<sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="87"><highlight class="normal"><sp/><sp/>m_initialized<sp/>=<sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="88"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="89"><highlight class="normal">}</highlight></codeline>
<codeline lineno="90"><highlight class="normal"></highlight></codeline>
<codeline lineno="103"><highlight class="normal"></highlight><highlight class="keywordtype">bool</highlight><highlight class="normal"><sp/><ref refid="classemulator_1_1inference_1_1LibTorchBackend_1ac9850ff1056a6364b5d765d2105a8302" kindref="member">LibTorchBackend::infer</ref>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>*inputs,<sp/></highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>*outputs,</highlight></codeline>
<codeline lineno="104"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>batch_size)<sp/>{</highlight></codeline>
<codeline lineno="105"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!m_initialized<sp/>||<sp/>!m_impl<sp/>||<sp/>!m_impl-&gt;model_loaded)<sp/>{</highlight></codeline>
<codeline lineno="106"><highlight class="normal"><sp/><sp/><sp/><sp/>std::cerr<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;[LibTorchBackend::infer]<sp/>ERROR:<sp/>Backend<sp/>not<sp/>initialized!&quot;</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="107"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&lt;&lt;<sp/>std::endl;</highlight></codeline>
<codeline lineno="108"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="109"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="110"><highlight class="normal"></highlight></codeline>
<codeline lineno="111"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>C_in<sp/>=<sp/>m_config.input_channels;</highlight></codeline>
<codeline lineno="112"><highlight class="normal"><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">int</highlight><highlight class="normal"><sp/>C_out<sp/>=<sp/>m_config.output_channels;</highlight></codeline>
<codeline lineno="113"><highlight class="normal"></highlight></codeline>
<codeline lineno="114"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">try</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="115"><highlight class="normal"><sp/><sp/><sp/><sp/>torch::NoGradGuard<sp/>no_grad;</highlight></codeline>
<codeline lineno="116"><highlight class="normal"></highlight></codeline>
<codeline lineno="117"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Create<sp/>input<sp/>tensor<sp/>by<sp/>wrapping<sp/>the<sp/>pointer<sp/>directly</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="118"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>EmulatorAtm<sp/>has<sp/>already<sp/>arranged<sp/>data<sp/>in<sp/>the<sp/>correct<sp/>shape:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="119"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>-<sp/>Spatial<sp/>mode:<sp/>[batch_size,<sp/>C,<sp/>H,<sp/>W]<sp/>flattened</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="120"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>-<sp/>Pointwise<sp/>mode:<sp/>[batch_size,<sp/>C]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="121"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;int64_t&gt;<sp/>input_shape;</highlight></codeline>
<codeline lineno="122"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(m_config.spatial_mode)<sp/>{</highlight></codeline>
<codeline lineno="123"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>input_shape<sp/>=<sp/>{batch_size,<sp/>C_in,<sp/>m_config.grid_height,</highlight></codeline>
<codeline lineno="124"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m_config.grid_width};</highlight></codeline>
<codeline lineno="125"><highlight class="normal"><sp/><sp/><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">else</highlight><highlight class="normal"><sp/>{</highlight></codeline>
<codeline lineno="126"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>input_shape<sp/>=<sp/>{batch_size,<sp/>C_in};</highlight></codeline>
<codeline lineno="127"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="128"><highlight class="normal"></highlight></codeline>
<codeline lineno="129"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>We<sp/>assume<sp/>inputs<sp/>are<sp/>in<sp/>double<sp/>precision<sp/>(Float64)<sp/>and<sp/>on<sp/>host</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="130"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>make<sp/>this<sp/>configurable<sp/>if<sp/>needed</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="131"><highlight class="normal"><sp/><sp/><sp/><sp/>torch::Tensor<sp/>input_tensor<sp/>=<sp/>torch::from_blob(</highlight></codeline>
<codeline lineno="132"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const_cast&lt;</highlight><highlight class="keywordtype">double</highlight><highlight class="normal"><sp/>*</highlight><highlight class="keyword">&gt;</highlight><highlight class="normal">(inputs),<sp/>input_shape,</highlight></codeline>
<codeline lineno="133"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU));</highlight></codeline>
<codeline lineno="134"><highlight class="normal"></highlight></codeline>
<codeline lineno="135"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Convert<sp/>to<sp/>model<sp/>dtype<sp/>(Float32)<sp/>and<sp/>target<sp/>device</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="136"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>make<sp/>EmulatorComp<sp/>sends<sp/>us<sp/>the<sp/>right<sp/>dtype</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="137"><highlight class="normal"><sp/><sp/><sp/><sp/>input_tensor<sp/>=<sp/>input_tensor.to(m_impl-&gt;device,<sp/>m_impl-&gt;dtype);</highlight></codeline>
<codeline lineno="138"><highlight class="normal"></highlight></codeline>
<codeline lineno="139"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Execute<sp/>model<sp/>forward<sp/>pass</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="140"><highlight class="normal"><sp/><sp/><sp/><sp/>std::vector&lt;torch::jit::IValue&gt;<sp/>model_inputs;</highlight></codeline>
<codeline lineno="141"><highlight class="normal"><sp/><sp/><sp/><sp/>model_inputs.push_back(input_tensor);</highlight></codeline>
<codeline lineno="142"><highlight class="normal"></highlight></codeline>
<codeline lineno="143"><highlight class="normal"><sp/><sp/><sp/><sp/>torch::Tensor<sp/>output_tensor<sp/>=</highlight></codeline>
<codeline lineno="144"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>m_impl-&gt;model.forward(model_inputs).toTensor();</highlight></codeline>
<codeline lineno="145"><highlight class="normal"></highlight></codeline>
<codeline lineno="146"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Convert<sp/>output<sp/>back<sp/>to<sp/>Float64<sp/>on<sp/>CPU</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="147"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>TODO:<sp/>make<sp/>this<sp/>configurable<sp/>if<sp/>needed</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="148"><highlight class="normal"><sp/><sp/><sp/><sp/>output_tensor<sp/>=<sp/>output_tensor.to(torch::kCPU,<sp/>torch::kFloat64);</highlight></codeline>
<codeline lineno="149"><highlight class="normal"></highlight></codeline>
<codeline lineno="150"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Ensure<sp/>contiguous<sp/>and<sp/>copy</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="151"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">if</highlight><highlight class="normal"><sp/>(!output_tensor.is_contiguous())<sp/>{</highlight></codeline>
<codeline lineno="152"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/>output_tensor<sp/>=<sp/>output_tensor.contiguous();</highlight></codeline>
<codeline lineno="153"><highlight class="normal"><sp/><sp/><sp/><sp/>}</highlight></codeline>
<codeline lineno="154"><highlight class="normal"></highlight></codeline>
<codeline lineno="155"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>Output<sp/>shape<sp/>matches<sp/>what<sp/>EmulatorComp<sp/>expects:</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="156"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>-<sp/>Spatial:<sp/>[batch_size,<sp/>C,<sp/>H,<sp/>W]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="157"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="comment">//<sp/>-<sp/>Pointwise:<sp/>[batch_size,<sp/>C]</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="158"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/>output_size<sp/>=<sp/>output_tensor.numel();</highlight></codeline>
<codeline lineno="159"><highlight class="normal"><sp/><sp/><sp/><sp/>std::memcpy(outputs,<sp/>output_tensor.data_ptr&lt;</highlight><highlight class="keywordtype">double</highlight><highlight class="normal">&gt;(),</highlight></codeline>
<codeline lineno="160"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>output_size<sp/>*<sp/></highlight><highlight class="keyword">sizeof</highlight><highlight class="normal">(</highlight><highlight class="keywordtype">double</highlight><highlight class="normal">));</highlight></codeline>
<codeline lineno="161"><highlight class="normal"></highlight></codeline>
<codeline lineno="162"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">catch</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>c10::Error<sp/>&amp;e)<sp/>{</highlight></codeline>
<codeline lineno="163"><highlight class="normal"><sp/><sp/><sp/><sp/>std::cerr<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;[LibTorchBackend::infer]<sp/>FATAL<sp/>c10::Error:<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>e.what()</highlight></codeline>
<codeline lineno="164"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&lt;&lt;<sp/>std::endl;</highlight></codeline>
<codeline lineno="165"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="166"><highlight class="normal"><sp/><sp/>}<sp/></highlight><highlight class="keywordflow">catch</highlight><highlight class="normal"><sp/>(</highlight><highlight class="keyword">const</highlight><highlight class="normal"><sp/>std::exception<sp/>&amp;e)<sp/>{</highlight></codeline>
<codeline lineno="167"><highlight class="normal"><sp/><sp/><sp/><sp/>std::cerr<sp/>&lt;&lt;<sp/></highlight><highlight class="stringliteral">&quot;[LibTorchBackend::infer]<sp/>FATAL<sp/>exception:<sp/>&quot;</highlight><highlight class="normal"><sp/>&lt;&lt;<sp/>e.what()</highlight></codeline>
<codeline lineno="168"><highlight class="normal"><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/><sp/>&lt;&lt;<sp/>std::endl;</highlight></codeline>
<codeline lineno="169"><highlight class="normal"><sp/><sp/><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="170"><highlight class="normal"><sp/><sp/>}</highlight></codeline>
<codeline lineno="171"><highlight class="normal"></highlight></codeline>
<codeline lineno="172"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/></highlight><highlight class="keyword">true</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="173"><highlight class="normal">}</highlight></codeline>
<codeline lineno="174"><highlight class="normal"></highlight></codeline>
<codeline lineno="175"><highlight class="normal"></highlight><highlight class="keywordtype">void</highlight><highlight class="normal"><sp/><ref refid="classemulator_1_1inference_1_1LibTorchBackend_1a8c849a1784ce1e351fdd2a6c5b86639f" kindref="member">LibTorchBackend::finalize</ref>()<sp/>{</highlight></codeline>
<codeline lineno="176"><highlight class="normal"><sp/><sp/>m_impl.reset();</highlight></codeline>
<codeline lineno="177"><highlight class="normal"><sp/><sp/>m_initialized<sp/>=<sp/></highlight><highlight class="keyword">false</highlight><highlight class="normal">;</highlight></codeline>
<codeline lineno="178"><highlight class="normal">}</highlight></codeline>
<codeline lineno="179"><highlight class="normal"></highlight></codeline>
<codeline lineno="180"><highlight class="normal"></highlight><highlight class="keywordtype">size_t</highlight><highlight class="normal"><sp/><ref refid="classemulator_1_1inference_1_1LibTorchBackend_1a222ca3846212cabcd74d96183c169900" kindref="member">LibTorchBackend::get_memory_usage_bytes</ref>()</highlight><highlight class="keyword"><sp/>const<sp/></highlight><highlight class="normal">{</highlight></codeline>
<codeline lineno="181"><highlight class="normal"><sp/><sp/></highlight><highlight class="keywordflow">return</highlight><highlight class="normal"><sp/>m_model_memory_bytes;</highlight></codeline>
<codeline lineno="182"><highlight class="normal">}</highlight></codeline>
<codeline lineno="183"><highlight class="normal"></highlight></codeline>
<codeline lineno="184"><highlight class="normal">}<sp/></highlight><highlight class="comment">//<sp/>namespace<sp/>inference</highlight><highlight class="normal"></highlight></codeline>
<codeline lineno="185"><highlight class="normal">}<sp/></highlight><highlight class="comment">//<sp/>namespace<sp/>emulator</highlight><highlight class="normal"></highlight></codeline>
    </programlisting>
    <location file="components/emulator_comps/common/src/inference/libtorch_backend.cpp"/>
  </compounddef>
</doxygen>

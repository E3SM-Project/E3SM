<?xml version="1.0"?>
<config_batch version="2.0">
  <!--
     File:    config_batch.xml
     Purpose: abstract out the parts of run scripts that are different, and use this configuration to
     create acme run scripts from a single template.

     batch_system:     the batch system type and version
     batch_query:      the batch query command for each batch system.
     batch_redirect:   Whether a redirect character is needed to submit jobs.
     batch_directive:  The string that prepends a batch directive for the batch system.
     jobid_pattern:    A perl regular expression used to filter out the returned job id from a
                       queue submission.
     depend_pattern:

 ===============================================================
 batch_system
 ===============================================================
 The batch_system and associated tags are meant for configuring batch systems and
 queues across machines.  The batch_system tag denotes the name for a particular
 batch system, these can either be shared between one or more machines, or can be
 defined for a specific machine if need be.

 Machine specific entries take precidence over generic entries, directives are appended

 queues:
 one or more queues can be defined per batch_system. if the attribute default="true"
 is used, then that queue will be used by default. Alternatively, multiple queues can
 be used.  The following variables can be used to choose a queue :
 walltimemin: Giving the minimum amount of walltime for the queue.
 walltimemax: The maximum amount of walltime for a queue.
 nodemin:      The minimum node count required to use this queue.
 nodemax:      The maximum node count required to use this queue.
 jobmin:      The minimum task count required to use this queue. This should only rarely be used to select queues that only use a fraction of a node. This cannot be used in conjuction with nodemin.
 jobmax:      The maximum task count required to use this queue. This should only rarely be used to select queues that only use a fraction of a node. This cannot be used in conjuction with nodemax.
    -->
  <batch_system type="template" >
    <batch_query args=""></batch_query>
    <batch_submit></batch_submit>
    <batch_cancel></batch_cancel>
    <batch_redirect></batch_redirect>
    <batch_directive></batch_directive>
    <directives>
      <directive></directive>
    </directives>
  </batch_system>

  <batch_system type="none" >
    <batch_query args=""></batch_query>
    <batch_submit></batch_submit>
    <batch_cancel></batch_cancel>
    <batch_redirect></batch_redirect>
    <batch_directive></batch_directive>
    <directives>
      <directive></directive>
    </directives>
  </batch_system>

  <batch_system type="cobalt" >
    <batch_query>qstat</batch_query>
    <batch_submit>qsub</batch_submit>
    <batch_cancel>qdel</batch_cancel>
    <batch_env>--env</batch_env>
    <batch_directive></batch_directive>
    <jobid_pattern>(\d+)</jobid_pattern>
    <depend_string> --dependencies</depend_string>
    <walltime_format>%H:%M:%s</walltime_format>
    <batch_mail_flag>-M</batch_mail_flag>
    <batch_mail_type_flag></batch_mail_type_flag>
    <batch_mail_type></batch_mail_type>
    <submit_args>
      <arg flag="--cwd" name="CASEROOT"/>
      <arg flag="-A" name="CHARGE_ACCOUNT"/>
      <arg flag="-t" name="JOB_WALLCLOCK_TIME"/>
      <arg flag="-n" name=" ($TOTALPES + $MAX_MPITASKS_PER_NODE - 1)/$MAX_MPITASKS_PER_NODE"/>
      <arg flag="-q" name="JOB_QUEUE"/>
      <arg flag="--mode script"/>
    </submit_args>
  </batch_system>

  <batch_system type="cobalt_theta" >
    <batch_query>qstat</batch_query>
    <batch_submit>/projects/ccsm/acme/tools/cobalt/dsub</batch_submit>
    <batch_cancel>qdel</batch_cancel>
    <batch_env>--env</batch_env>
    <batch_directive>#COBALT</batch_directive>
    <jobid_pattern>(\d+)</jobid_pattern>
    <depend_string>--dependencies jobid</depend_string>
    <depend_separator>:</depend_separator>
    <batch_mail_flag>-M</batch_mail_flag>
    <batch_mail_type_flag></batch_mail_type_flag>
    <batch_mail_type></batch_mail_type>
    <submit_args>
      <arg flag="-A" name="$PROJECT"/>
      <arg flag="-t" name="JOB_WALLCLOCK_TIME"/>
      <arg flag="-n" name=" ($TOTALPES + $MAX_MPITASKS_PER_NODE - 1)/$MAX_MPITASKS_PER_NODE"/>
      <arg flag="-q" name="JOB_QUEUE"/>
      <arg flag="--mode script"/>
    </submit_args>
  </batch_system>

<!-- This is the new version on Summit, released as IBM 10.1.0.0 build 476197, Nov 21 2017.  -->
  <batch_system type="lsf" version="10.1">
    <batch_query args=" -w" >bjobs</batch_query>
    <batch_submit>bsub</batch_submit>
    <batch_cancel>bkill</batch_cancel>
    <batch_env>-env</batch_env>
    <batch_directive>#BSUB</batch_directive>
    <jobid_pattern>&lt;(\d+)&gt;</jobid_pattern>
    <depend_string> -w 'done(jobid)'</depend_string>
    <depend_allow_string> -w 'ended(jobid)'</depend_allow_string>
    <depend_separator>&amp;&amp;</depend_separator>
    <walltime_format>%H:%M</walltime_format>
    <batch_mail_flag>-u</batch_mail_flag>
    <batch_mail_type_flag> </batch_mail_type_flag>
    <batch_mail_type>, -B -N, -B,-N,-N</batch_mail_type>
    <submit_args>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="-W" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-P" name="$CHARGE_ACCOUNT"/>
    </submit_args>
    <directives>
      <directive                       > -nnodes {{ num_nodes }} </directive>
      <directive default="e3sm.stdout" > -o {{ output_error_path }}.%J  </directive>
      <directive default="e3sm.stderr" > -e {{ output_error_path }}.%J  </directive>
      <directive                       > -J {{ job_id }} </directive>
    </directives>
  </batch_system>

  <batch_system type="pbs" >
    <batch_query args="-f" >qstat</batch_query>
    <batch_submit>qsub </batch_submit>
    <batch_cancel>qdel</batch_cancel>
    <batch_env>-v</batch_env>
    <batch_directive>#PBS</batch_directive>
    <jobid_pattern>^(\S+)$</jobid_pattern>
    <depend_string>-W depend=afterok:jobid</depend_string>
    <depend_allow_string>-W depend=afterany:jobid</depend_allow_string>
    <depend_separator>:</depend_separator>
    <walltime_format>%H:%M:%S</walltime_format>
    <batch_mail_flag>-M</batch_mail_flag>
    <batch_mail_type_flag>-m</batch_mail_type_flag>
    <batch_mail_type>, bea, b, e, a</batch_mail_type>
    <submit_args>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="-l walltime=" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-A" name="$CHARGE_ACCOUNT"/>
    </submit_args>
    <directives>
      <directive> -N {{ job_id }}</directive>
      <directive default="n"> -r {{ rerunnable }} </directive>
      <!-- <directive> -j oe {{ job_id }} </directive> -->
      <directive> -j oe </directive>
      <directive> -V </directive>
    </directives>
  </batch_system>

  <batch_system type="moab" >
    <batch_query>showq</batch_query>
    <batch_submit>msub </batch_submit>
    <batch_cancel>canceljob</batch_cancel>
    <batch_directive>#MSUB</batch_directive>
    <jobid_pattern>(\d+)$</jobid_pattern>
    <depend_string>-W depend=afterok:jobid</depend_string>
    <depend_allow_string>-W depend=afterany:jobid</depend_allow_string>
    <depend_separator>:</depend_separator>
    <walltime_format>%H:%M:%S</walltime_format>
    <batch_mail_flag>-M</batch_mail_flag>
    <batch_mail_type_flag>-m</batch_mail_type_flag>
    <batch_mail_type>, bea, b, e, a</batch_mail_type>
    <submit_args>
      <arg flag="-l walltime=" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-A" name="$CHARGE_ACCOUNT"/>
    </submit_args>
    <directives>
      <directive> -N {{ job_id }}</directive>
      <directive> -j oe </directive>
      <directive default="n"> -r {{ rerunnable }} </directive>
      <directive default="/bin/bash" > -S {{ shell }}</directive>
    </directives>
  </batch_system>

  <!-- for lawrence livermore computing -->
  <batch_system type="lc_slurm">
    <batch_query per_job_arg="-j">squeue</batch_query>
    <batch_submit>sbatch</batch_submit>
    <batch_cancel>scancel</batch_cancel>
    <batch_directive>#SBATCH</batch_directive>
    <jobid_pattern>(\d+)$</jobid_pattern>
    <depend_string>--dependency=afterok:jobid</depend_string>
    <depend_allow_string>--dependency=afterany:jobid</depend_allow_string>
    <depend_separator>:</depend_separator>
    <walltime_format>%H:%M:%S</walltime_format>
    <batch_mail_flag>--mail-user</batch_mail_flag>
    <batch_mail_type_flag>--mail-type</batch_mail_type_flag>
    <batch_mail_type>none, all, begin, end, fail</batch_mail_type>
    <directives>
      <directive>--export=ALL</directive>
      <directive>-p {{ job_queue }}</directive>
      <directive>-J {{ job_id }}</directive>
      <directive>-N {{ num_nodes }}</directive>
      <directive>-n {{ total_tasks }}</directive>
      <directive>-t {{ job_wallclock_time }}</directive>
      <directive>-o {{ job_id }}.out</directive>
      <directive>-e {{ job_id }}.err</directive>
      <directive> -A {{ project }} </directive>
    </directives>
    <queues>
      <queue walltimemax="01:00:00" nodemax="270" default="true">pbatch</queue>
      <queue walltimemax="00:30:00">pdebug</queue>
    </queues>
  </batch_system>
  <!-- for lawrence livermore computing -->

  <!-- for NERSC machines: edison,cori-haswell,cori-knl -->
  <batch_system type="nersc_slurm" >
    <batch_query per_job_arg="-j">squeue</batch_query>
    <batch_submit>sbatch</batch_submit>
    <batch_cancel>scancel</batch_cancel>
    <batch_directive>#SBATCH</batch_directive>
    <jobid_pattern>(\d+)$</jobid_pattern>
    <depend_string>--dependency=afterok:jobid</depend_string>
    <depend_allow_string>--dependency=afterany:jobid</depend_allow_string>
    <depend_separator>:</depend_separator>
    <walltime_format>%H:%M:%S</walltime_format>
    <batch_mail_flag>--mail-user</batch_mail_flag>
    <batch_mail_type_flag>--mail-type</batch_mail_type_flag>
    <batch_mail_type>none, all, begin, end, fail</batch_mail_type>
    <submit_args>
      <arg flag="--time" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-q" name="$JOB_QUEUE"/>
      <arg flag="--account" name="$PROJECT"/>
    </submit_args>
    <directives>
      <directive> --job-name={{ job_id }}</directive>
      <directive> --nodes={{ num_nodes }}</directive>
      <directive> --output={{ job_id }}.%j </directive>
      <directive> --exclusive </directive>
    </directives>
  </batch_system>

  <batch_system type="slurm" >
    <batch_query per_job_arg="-j">squeue</batch_query>
    <batch_submit>sbatch</batch_submit>
    <batch_cancel>scancel</batch_cancel>
    <batch_directive>#SBATCH</batch_directive>
    <jobid_pattern>(\d+)$</jobid_pattern>
    <depend_string>--dependency=afterok:jobid</depend_string>
    <depend_allow_string>--dependency=afterany:jobid</depend_allow_string>
    <depend_separator>:</depend_separator>
    <walltime_format>%H:%M:%S</walltime_format>
    <batch_mail_flag>--mail-user</batch_mail_flag>
    <batch_mail_type_flag>--mail-type</batch_mail_type_flag>
    <batch_mail_type>none, all, begin, end, fail</batch_mail_type>
    <submit_args>
      <arg flag="--time" name="$JOB_WALLCLOCK_TIME"/>
      <arg flag="-p" name="$JOB_QUEUE"/>
      <arg flag="--account" name="$PROJECT"/>
    </submit_args>
    <directives>
      <directive> --job-name={{ job_id }}</directive>
      <directive> --nodes={{ num_nodes }}</directive>
      <directive> --output={{ job_id }}.%j </directive>
      <directive> --exclusive </directive>
    </directives>
  </batch_system>

    <!-- blues is PBS -->
    <batch_system MACH="blues" type="pbs" >
      <directives>
        <directive>-A {{ PROJECT }}</directive>
        <directive>-l nodes={{ num_nodes }}:ppn={{ tasks_per_node }}</directive>
      </directives>
      <queues>
	<queue walltimemax="01:00:00" nodemax="4" strict="true">shared</queue>
	<queue walltimemax="03:00:00" default="true">batch</queue>
      </queues>
    </batch_system>

    <!-- anvil is PBS -->
    <batch_system MACH="anvil" type="pbs" >
      <directives>
        <directive>-A {{ PROJECT }}</directive>
        <directive>-l nodes={{ num_nodes }}:ppn={{ tasks_per_node }}</directive>
      </directives>
      <queues>
	<queue walltimemax="01:00:00" default="true">acme</queue>
      </queues>
    </batch_system>

    <batch_system MACH="bebop" type="slurm" >
      <queues>
	<queue walltimemax="00:30:00" nodemax="64" strict="true">debug</queue>
        <queue walltimemax="01:00:00" nodemax="608" default="true">bdw</queue>
        <queue walltimemax="01:00:00" nodemax="512">knl</queue>
      </queues>
    </batch_system>

    <!-- eos is PBS -->
    <batch_system MACH="eos" type="pbs" >
    <directives>
      <directive>-A {{ project }}</directive>
      <directive>-l  nodes={{ num_nodes }}</directive>
    </directives>
    <queues>
      <queue walltimemax="00:30:00" default="true">batch</queue>
    </queues>
   </batch_system>

  <batch_system MACH="edison" type="nersc_slurm" >
    <queues>
      <queue walltimemax="00:30:00" nodemax="512" strict="true">debug</queue>
      <queue walltimemax="01:30:00" default="true">regular</queue>
    </queues>
  </batch_system>

  <batch_system MACH="cori-haswell" type="nersc_slurm">
     <directives>
       <directive> --constraint=haswell</directive>
     </directives>
     <queues>
       <queue walltimemax="00:30:00" nodemax="64" strict="true">debug</queue>
       <queue walltimemax="01:00:00" default="true">regular</queue>
     </queues>
  </batch_system>

  <batch_system MACH="cori-knl" type="nersc_slurm">
    <directives>
      <directive> --constraint=knl,quad,cache</directive>
    </directives>
    <queues>
      <queue walltimemax="00:30:00" nodemax="512" strict="true">debug</queue>
      <queue walltimemax="01:15:00" default="true">regular</queue>
    </queues>
  </batch_system>

  <batch_system MACH="stampede2" type="slurm">
    <directives>
      <directive>-n {{ total_tasks }}</directive>
    </directives>
    <queues>
      <queue walltimemax="00:30:00" nodemax="4" strict="true">skx-dev</queue>
      <queue walltimemax="00:30:00" nodemax="868" strict="true">skx-large</queue>
      <queue walltimemax="01:00:00" nodemax="128" default="true">skx-normal</queue>
    </queues>
  </batch_system>

    <batch_system MACH="mira" type="cobalt">
      <queues>
        <queue walltimemax="03:00:00" default="true">default</queue>
      </queues>
    </batch_system>

    <batch_system MACH="cetus" type="cobalt">
      <queues>
        <queue walltimemax="01:00:00" default="true">default</queue>
      </queues>
    </batch_system>

    <batch_system MACH="theta" type="cobalt_theta">
      <queues>
        <queue walltimemax="01:00:00" nodemax="8" strict="true">debug-cache-quad</queue>
        <queue walltimemin="00:30:00" walltimemax="02:00:00" nodemin="8" nodemax="15" strict="true">default</queue>
        <queue walltimemin="00:30:00" walltimemax="04:00:00" nodemin="16" nodemax="127" strict="true">default</queue>
        <queue walltimemin="00:30:00" walltimemax="06:00:00" nodemin="128" nodemax="383" strict="true">default</queue>
        <queue walltimemin="00:30:00" walltimemax="12:00:00" nodemin="384" nodemax="647" strict="true">default</queue>
        <queue walltimemin="00:30:00" walltimemax="24:00:00" nodemin="648" strict="true" default="true">default</queue>
      </queues>
    </batch_system>

    <batch_system MACH="jlse" type="cobalt_theta">
      <batch_submit>qsub</batch_submit>
      <queues>
        <queue walltimemax="01:00:00" jobmin="1" jobmax="20" default="true">skylake_8180</queue>
      </queues>
    </batch_system>

    <batch_system MACH="cascade" type="slurm">
      <directives>
	<directive>--output=slurm.out</directive>
	<directive>--error=slurm.err</directive>
      </directives>
      <queues>
	<queue walltimemax="00:59:00" nodemin="1"  nodemax="15"  >small</queue>
	<queue walltimemax="00:59:00" nodemin="16" nodemax="127" >medium</queue>
	<queue walltimemax="00:59:00" nodemin="128" default="true" >large</queue>
      </queues>
    </batch_system>

   <batch_system MACH="constance" type="slurm">
    <directives>
      <directive>--output=slurm.out</directive>
      <directive>--error=slurm.err</directive>
    </directives>
    <queues>
      <queue walltimemax="00:59:00" default="true">slurm</queue>
    </queues>
   </batch_system>

   <batch_system MACH="sooty" type="slurm" >
     <directives>
       <directive>--ntasks-per-node={{ tasks_per_node }}</directive>
       <directive>--output=slurm.out</directive>
       <directive>--error=slurm.err</directive>
     </directives>
     <queues>
       <queue walltimemax="00:59:00" default="true">slurm</queue>
     </queues>
   </batch_system>

  <batch_system MACH="sandiatoss3" type="slurm" >
    <queues>
      <queue nodemax="12" walltimemax="04:00:00" strict="true" default="true">short</queue>
      <queue walltimemax="24:00:00">batch</queue>
    </queues>
  </batch_system>

  <batch_system MACH="ghost" type="slurm" >
    <queues>
      <queue nodemax="12" walltimemax="04:00:00" strict="true" default="true">short</queue>
      <queue walltimemax="24:00:00">batch</queue>
    </queues>
  </batch_system>

  <batch_system MACH="mustang" type="moab" >
    <directives>
      <directive>-l nodes={{ num_nodes }}:ppn={{ tasks_per_node }}</directive>
    </directives>
  </batch_system>

  <batch_system MACH="grizzly" type="slurm" >
	<directives>
		<directive>--nodes={{ num_nodes }}</directive>
		<directive>--ntasks-per-node={{ tasks_per_node }}</directive>
		<directive>--qos=standard </directive>
	</directives>
	<queues>
		<queue walltimemax="16:00:00" default="true">standard</queue>
	</queues>
  </batch_system>

   <batch_system MACH="wolf" type="slurm" >
	<directives>
		<directive>--nodes={{ num_nodes }}</directive>
		<directive>--ntasks-per-node={{ tasks_per_node }}</directive>
		<directive>--qos=standard </directive>
	</directives>
	<queues>
		<queue walltimemax="16:00:00" default="true">standard</queue>
	</queues>
    </batch_system>

    <batch_system MACH="mesabi" type="pbs">
      <queues>
        <queue walltimemax="24:00" default="true">mesabi</queue>
        <queue walltimemax="24:00">debug</queue>
      </queues>
    </batch_system>

   <batch_system MACH="oic5" type="pbs" >
         <directives>
                 <directive>-l nodes={{ num_nodes }}:ppn={{ tasks_per_node }}</directive>
		 <directive>-q esd13q</directive>
         </directives>
         <queues>
           <queue default="true">esd13q</queue>
           <queue walltimemax="1:00">esddbg13q</queue>
         </queues>
   </batch_system>

   <batch_system MACH="cades" type="pbs" >
         <directives>
                 <directive>-l nodes={{ num_nodes }}:ppn={{ tasks_per_node }}</directive>
                 <directive>-W group_list=cades-ccsi</directive>
         </directives>
         <queues>
           <queue default="true">batch</queue>
         </queues>
   </batch_system>

   <batch_system MACH="itasca" type="pbs">
     <queues>
       <queue walltimemax="24:00" default="true">batch</queue>
       <queue walltimemax="24:00">debug</queue>
     </queues>
   </batch_system>

   <batch_system MACH="titan" type="pbs" >
     <directives>
       <directive>-A {{ project }}</directive>
       <directive>-l nodes={{ num_nodes }}</directive>
       <directive>-env "all"</directive>
     </directives>
     <queues>
       <queue walltimemax="02:00:00" default="true">batch</queue>
       <queue walltimemax="01:00:00" nodemax="18688" strict="true">debug</queue>
     </queues>
   </batch_system>

   <batch_system MACH="summit" type="lsf" >
     <directives>
       <directive>-P {{ project }}</directive>
     </directives>
     <directives compiler="!pgiacc">
       <directive>-alloc_flags smt2</directive>
     </directives>
     <directives compiler="pgiacc">
       <directive>-alloc_flags "gpumps smt2"</directive>
     </directives>
     <queues>
       <queue walltimemax="02:00" default="true">batch</queue>
     </queues>
   </batch_system>


   <batch_system MACH="summitdev" type="lsf" >
     <directives>
       <directive>-P {{ project }}</directive>
       <directive>-alloc_flags gpumps</directive>
     </directives>

     <queues>
       <queue walltimemax="01:00" default="true">batch</queue>
	   <!--
	   Nodes	Max Walltime
	   <=4		4 hours
	   >4		1 hour
	   jobmax = 54nodes*20cores*16th = 8640
	   -->
     </queues>
   </batch_system>

   <batch_system MACH="snl-white" type="lsf" >
     <queues>
       <queue walltimemax="02:00" default="true">rhel7G</queue>
     </queues>
   </batch_system>

   <batch_system MACH="snl-blake" type="slurm" >
     <queues>
       <queue walltimemax="02:00" default="true">blake</queue>
     </queues>
   </batch_system>

   <batch_system MACH="lawrencium-lr2" type="slurm" >
     <directives>
       <directive>--ntasks-per-node={{ tasks_per_node }}</directive>
       <directive>--qos=condo_esd2 </directive>
     </directives>
    <queues>
      <queue walltimemax="01:00:00" default="true">lr3</queue>
    </queues>
   </batch_system>

   <batch_system MACH="lawrencium-lr3" type="slurm" >
     <directives>
       <directive>--ntasks-per-node={{ tasks_per_node }}</directive>
       <directive>--qos=condo_esd2 </directive>
     </directives>
    <queues>
      <queue walltimemax="01:00:00" default="true">lr3</queue>
    </queues>
   </batch_system>

  <batch_jobs>
    <!-- order matters, with no-batch jobs will be run in the order listed here -->
    <job name="case.run">
      <template>template.case.run</template>
      <prereq>$BUILD_COMPLETE and not $TEST</prereq>
    </job>
    <job name="case.run.sh">
      <template>template.case.run.sh</template>
      <prereq>False</prereq>
    </job>
   <job name="case.test">
      <template>template.case.test</template>
      <prereq>$BUILD_COMPLETE and $TEST</prereq>
    </job>
    <job name="case.st_archive">
      <template>template.st_archive</template>
      <task_count>1</task_count>
      <walltime>0:20:00</walltime>
      <!-- If DOUT_S is true and case.run (or case.test) exits successfully then run st_archive-->
      <dependency>case.run case.test</dependency>
      <prereq>$DOUT_S</prereq>
    </job>
  </batch_jobs>

</config_batch>

